{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84555411",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "\n",
    "Adaptive Boosting, is a Boosting technique used as an Ensemble Method in Machine Learning. It is called Adaptive Boosting as the weights are re-assigned to each instance, with higher weights assigned to incorrectly classified predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08699b7",
   "metadata": {},
   "source": [
    "Stump: It is a weak learner in the form of decision tree with depth 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af136",
   "metadata": {},
   "source": [
    "Gini purity shows the impurity.\n",
    "Gini impurity shows the purity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb13c81",
   "metadata": {},
   "source": [
    "Working of Adaboost:\n",
    "1. It assigns weights to each record in dataset. w = 1/n where n is no. of features in dataset. This will create new feature in dataset as weights.\n",
    "\n",
    "\n",
    "2. After assigning weights, it builds decision tree based on each feature with depth = 1. These DT are known as stumps.\n",
    "It gives the error of stump in prediction(what it predicted wrong vs actual)\n",
    "\n",
    "\n",
    "3. Then, it calculates performance of stump. in AdaBoost, records were allowed to pass and the wrong records are repeated more than the correct ones. We must increase the weight for the wrongly classified records and decrease the weight for the correctly classified records. Every updated weight must be divided by the total sum of updated weight. These weights are known as normalized weights.\n",
    "\n",
    "\n",
    "4. After this it will previous stump predictions and fits these numbers into buckets. These buckets have range in which new prediction falls. There is a high probability for wrong records to get selected several times. Thats how adaboost focus on wrong records and try to get prediction correct next time.\n",
    "This will form the new dataset.\n",
    "\n",
    "\n",
    "Note: The adaboost model is assigning higher weights to wrongly classified. Its assigning more bucket size for wrong classified records. Therefore, for next predictions it will try to catch predictions which could fall into bucket. This is the trick behind adaboost.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cb6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d12da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c2fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43824f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abd1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
